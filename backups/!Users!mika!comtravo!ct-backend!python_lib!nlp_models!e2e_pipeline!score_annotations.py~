import numpy as np
from helpers import ann_start, ann_end


def score_annotations(keys, responses):
    """Score the quality of the annotations in response (prediction)
    compared to those in key (truth) a long the lines of
    http://www.aclweb.org/website/old_anthology/M/M93/M93-1007.pdf"""
    counts = {
        # count number of elements in response for which there is an
        # element in key such that:
        'correct': 0,  # correct: same span, same type
        'partial': 0,  # partial: spans overlap, same type
        'incorrect': 0,  # incorrect: spans overlap, different type
        'spurious': 0,  # spurious: number of response elements that do not overlap a key element
        'missing': 0  # missing: number of key elements that do not overlap a response element
    }
    # calculate counts for body and subject

    def assert_spans_disjoint(ann):
        cover_body = []
        cover_subject = []
        for a in ann:
            for s in a['spans']:
                if a['where'] == 'body':
                    if len(np.intersect1d(cover_body, range(s['start'], s['end']))) != 0:
                        return False
                    cover_body += range(s['start'], s['end'])
                else:
                    if len(np.intersect1d(cover_subject, range(s['start'], s['end']))) != 0:
                        return False
                    cover_subject += range(s['start'], s['end'])
        return True

    if not assert_spans_disjoint(keys):
        return None
    # assert_spans_disjoint(responses)

    for where in ['subject', 'body']:
        # sort keys and responses by start of span where annotations
        # with the same start are ordered by total length of the
        # annotation
        s_keys = sorted(sorted([k for k in keys if k['where'] == where],
                               key=lambda x: ann_end(x) - ann_start(x)),
                        key=lambda x: ann_start(x))
        s_responses = sorted(sorted([r for r in responses if r['where'] == where],
                                    key=lambda x: ann_end(x) - ann_start(x)),
                             key=lambda x: ann_start(x))
        ik = 0
        # iterate over all responses
        for ir, r in enumerate(s_responses):
            r_start = ann_start(r)
            # search head of keys list:
            # - as long as the key ends *before* the current response -> missing
            #   move on to next key
            while ik < len(s_keys) and ann_end(s_keys[ik]) <= r_start:
                counts['missing'] += 1
                ik += 1
            # - the head key starts *after* the current response or there
            #   are no further keys -> spurious
            #   continue with next response
            r_end = ann_end(r)
            if (ik < len(s_keys) and r_end <= ann_start(s_keys[ik])) or ik == len(s_keys):
                counts['spurious'] += 1
            # - otherwise while there are (i) key elements left and (ii)
            #   they overlap with the response (i.e.  r_start <
            #   ann_end(keys[ik]) and r_end > ann_start(keys[ik]), check
            #   whether the overlap is correct, partial or incorrect
            else:
                k_start = ann_start(s_keys[ik])
                k_end = ann_end(s_keys[ik])
                while ik < len(s_keys) and r_start < k_end and r_end > k_start:
                    if s_keys[ik]['type'] != r['type']:
                        # - type mismatch -> incorrect
                        counts['incorrect'] += 1
                    elif r_start == k_start and r_end == k_end:
                        # - perfect match -> correct
                        #   move on to next response
                        counts['correct'] += 1
                        ik += 1
                        break
                    else:
                        # - partial match -> partial
                        counts['partial'] += 1
                    ik += 1
                    if ik < len(s_keys):
                        k_start = ann_start(s_keys[ik])
                        k_end = ann_end(s_keys[ik])
    # calculate metrics
    wrong = counts['incorrect'] + counts['partial']/2.0 + counts['missing'] + counts['spurious']
    total = (counts['correct'] + counts['partial'] + counts['incorrect'] +
             counts['missing'] + counts['spurious'])
    possible = counts['correct'] + counts['partial'] + counts['incorrect'] + counts['missing']
    actual = counts['correct'] + counts['partial'] + counts['incorrect'] + counts['spurious']

    score = {'counts': counts}
    score['error_per_response_fill'] = wrong/total if total > 0 else 0.0
    score['undergeneration'] = counts['missing']/possible if possible > 0 else 0.0
    score['overgeneration'] = counts['spurious']/actual if actual > 0 else 0.0
    tmp = counts['correct'] + counts['partial'] + counts['incorrect']
    score['substitution'] = (counts['incorrect'] + counts['partial']/2.0)/tmp if tmp > 0 else 0.0

    score['recall'] = (counts['correct'] + counts['partial']/2.0)/possible if possible > 0 else 1.0
    score['precision'] = (counts['correct'] + counts['partial']/2.0)/actual if actual > 0 else 1.0
    return score
