import regex as re
import csv
from math import log10
import requests
import json
import sys


csv.field_size_limit(sys.maxsize)


iata_codes_per_geoname_id = {}
alternate_names = {}
with open('../../../geonames/alternateNames.txt', 'r', newline='') as f:
    for row in csv.reader(f, delimiter='\t'):
        gid = int(row[1])
        if row[2] == 'iata' and row[7] == '':
            if gid not in iata_codes_per_geoname_id:
                iata_codes_per_geoname_id[gid] = set()
            iata_codes_per_geoname_id[gid].add(row[3])
        elif ((row[4] == '1' or row[5] == '1') and
              (row[2] == 'de' or row[2] == 'en') and
              (row[7] == '')):
            # only preferred + short in en and de and not historical ones
            if gid not in alternate_names:
                alternate_names[gid] = set()
            alternate_names[gid].add(row[3])

names = [
    'geoname_id',  # integer id of record in geonames database
    'name',  # name of geographical point (utf8) varchar(200)
    'ascii_name',  # name of geographical point in plain ascii
                   # characters, varchar(200)
    'alternate_names',  # alternatenames, comma separated, ascii names
                        # automatically transliterated, convenience
                        # attribute from alternatename table,
                        # varchar(10000)
    'latitude',  # latitude in decimal degrees (wgs84)
    'longitude',  # longitude in decimal degrees (wgs84)
    'feature_class',  # see http://www.geonames.org/export/codes.html,
                      # char(1)
    'feature_code',  # see http://www.geonames.org/export/codes.html,
                     # varchar(10)
    'country_code',  # ISO-3166 2-letter country code, 2 characters
    'cc2',  # alternate country codes, comma separated, ISO-3166
            # 2-letter country code, 200 characters
    'admin1_code',  # fipscode (subject to change to iso code), see
                    # exceptions below, see file admin1Codes.txt for
                    # display names of this code; varchar(20)
    'admin2_code',  # code for the second administrative division, a
                    # county in the US, see file admin2Codes.txt;
                    # varchar(80)
    'admin3_code',  # code for third level administrative division,
                    # varchar(20)
    'admin4_code',  # code for fourth level administrative division,
                    # varchar(20)
    'population',  # bigint (8 byte int)
    'elevation',  # in meters, integer
    'dem',  # digital elevation model, srtm3 or gtopo30, average
            # elevation of 3''x3'' (ca 90mx90m) or 30''x30'' (ca
            # 900mx900m) area in meters, integer. srtm processed by
            # cgiar/ciat.
    'timezone',  # the timezone id (see file timeZone.txt) varchar(40)
    'modification_date'   # date of last modification in yyyy-MM-dd format
]

base_uri = 'http://192.168.99.100:9200/'

# Delete index
requests.delete('{}/geonames'.format(base_uri))

# Create index
requests.put('{}/geonames'.format(base_uri),
             data=json.dumps({
                 "settings": {
                     "analysis": {
                         "filter": {
                             "filter_shingle": {
                                 "type": "shingle",
                                 "max_shingle_size": 3,
                                 "min_shingle_size": 2,
                                 "output_unigrams": True
                             },
                             "filter_stop": {
                                 "type": "stop",
                                 "stopwords": ["airport", "air base", "ab", "flughafen"]
                             }
                         },
                         "analyzer": {
                             # "analyzer_keyword": {
                             #     "type": "custom",
                             #     "tokenizer": "keyword",
                             #     "filter": [
                             #         "asciifolding",
                             #         "lowercase"
                             #     ]
                             # },
                             "analyzer_shingle": {
                                 "type": "custom",
                                 "tokenizer": "standard",
                                 "filter": [
                                     "asciifolding",
                                     "lowercase",
                                     "filter_stop",
                                     "filter_shingle"
                                 ]
                             }
                         }
                     }
                 },
                 "mappings": {
                     "places": {
                         "properties": {
                             "name": {
                                 "type": "string",
                                 "analyzer": "analyzer_shingle"
                                 # "search_analyzer": "analyzer_shingle"
                             },
                             "alternate_names": {
                                 "type": "string",
                                 "analyzer": "analyzer_shingle"
                                 # "search_analyzer": "analyzer_shingle"
                             },
                             "location": {
                                 "type": "geo_point"
                             },
                             "iata_codes": {
                                 "type": "string",
                                 # do not lowercase, no tokenization required, etc.
                                 "index": "not_analyzed"
                             },
                             "feature_code": {
                                 "type": "string",
                                 "index": "not_analyzed"  # want to do wildcard expre on this
                             },
                             "feature_class": {
                                 "type": "string",
                                 "index": "not_analyzed"  # want to do wildcard expre on this
                             },
                             "admin1_code": {
                                 "type": "string",
                                 "index": "not_analyzed"
                             },
                             "admin2_code": {
                                 "type": "string",
                                 "index": "not_analyzed"
                             },
                             "admin3_code": {
                                 "type": "string",
                                 "index": "not_analyzed"
                             },
                             "admin4_code": {
                                 "type": "string",
                                 "index": "not_analyzed"
                             },
                             "country_code": {
                                 "type": "string",
                                 "index": "not_analyzed"
                             },
                             "cc2": {
                                 "type": "string",
                                 "index": "not_analyzed"
                             }
                         }
                     }
                 }
             }))


def query_es(query):
    """Given a dictionary of a query (the python json equivalent of what
    elasticsearch expects), run that query against travelers on
    bi.comtravo.com and return the result as dict

    """
    r = requests.get('http://192.168.99.100:9200/geonames/places/_search',
                     headers={'Accept': 'application/json', 'Content-Type': 'application/json'},
                     data=json.dumps(query))
    if r.status_code == 200:
        return r.json()['hits']['hits']
    else:
        return []


def resolve_parent(p):
    parents = []
    clause_adm4 = {"term": {"admin4_code": {"value": ""}}}
    clause_adm3 = {"term": {"admin3_code": {"value": ""}}}
    clause_adm2 = {"term": {"admin2_code": {"value": ""}}}
    clause_adm1 = {"term": {"admin1_code": {"value": "00"}}}
    clause_cc = {"term": {"country_code": {"value": p["country_code"]}}}
    clause_fcl = {"term": {"feature_class": {"value": "A"}}}
    clause_fco = {"term": {"feature_code": {"value": "PCLI"}}}
    res = query_es({"filter": {"bool": {"must": [
        clause_adm4,
        clause_adm3,
        clause_adm2,
        clause_adm1,
        clause_cc,
        clause_fcl,
        clause_fco]}}})
    if len(res) != 1:
        return parents
    else:
        parents.append(res[0])
    clause_adm1['term']['admin1_code']['value'] = p['admin1_code']
    clause_fco['term']['feature_code']['value'] = p['feature_code']
    if len(res) != 1:
        return parents
    else:
        parents.append(res[0])
    clause_adm2['term']['admin1_code']['value'] = p['admin2_code']
    if len(res) != 1:
        return parents
    else:
        parents.append(res[0])
    clause_adm3['term']['admin1_code']['value'] = p['admin3_code']
    if len(res) != 1:
        return parents
    else:
        parents.append(res[0])
    clause_adm4['term']['admin1_code']['value'] = p['admin4_code']
    if len(res) != 1:
        return parents
    else:
        parents.append(res[0])
    return parents


def bulk_insert(payload):
    uri = '{}_bulk'.format(base_uri)
    res = requests.put(uri, data=payload, headers={'Content-Type': 'application/json'})
    assert res.status_code == 200


cnt = 0
blk_size = 100000
blk_cnt = 0
blk_payload = ""
with open('../../../geonames/allCountries.txt', 'r', newline='', encoding='utf-8') as f:
    for row in csv.reader(f, delimiter='\t', quoting=csv.QUOTE_NONE):
        cnt += 1
        if cnt % 10000 == 0:
            print("at {}".format(cnt))
        rr = dict(zip(names, row))
        rr['geoname_id'] = int(rr['geoname_id'])
        rr['population'] = max(int(rr['population']), 0)
        rr['log_population'] = log10(1.0 + int(rr['population'])) + 1.0
        rr['location'] = {'lat': float(rr['latitude']), 'lon': float(rr['longitude'])}
        rr.pop('latitude')
        rr.pop('longitude')
        rr['elevation'] = int(rr['elevation']) if rr['elevation'] else None
        an = alternate_names.get(rr['geoname_id'], set())
        rr['alternate_names'] = list(an)
        # Limit length of longest alternative name - there are some
        # very long ones and/or there is a buggy line in the source
        # file; also exclude all fully capitalized alternate names
        # such as iata codes - they will match too much bogus text ('UND', 'THE', 'DAS', ...)
        rr['alternate_names'] = [a for a in rr['alternate_names'] if len(a) < 1000 and
                                 not re.match('^[A-Z]+$', a)]
        iata_code = iata_codes_per_geoname_id.get(rr['geoname_id'], set())
        rr['iata_codes'] = list(iata_code)
        rr['country_code'] = rr['country_code'].lower()
        rr['cc2'] = [cc.lower() for cc in rr['cc2']]
        parents = resolve_parent(rr)
        rr['parents'] = [p['_id'] for p in parents]
        if len(parents) > 0:
            print(rr['parents'])
        if blk_cnt >= blk_size:
            bulk_insert(blk_payload)
            blk_payload = ""
            blk_cnt = 0
        else:
            blk_cnt += 1
            blk_payload += '{"index": { "_index": "geonames", "_type": "places", "_id": "' + str(rr['geoname_id']) + '"} }\n'
            blk_payload += json.dumps(rr) + '\n'
# insert final batch
if blk_cnt > 0:
    bulk_insert(blk_payload)
print("FINISHED - INSERTED {} DOCUMENTS".format(cnt))
